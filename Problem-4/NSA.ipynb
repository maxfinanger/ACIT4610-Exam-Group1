{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850f5a7a-92f3-4c59-b324-f12d70afb02f",
   "metadata": {},
   "source": [
    "# NEGATIVE SELECTION ALGORITHM(NSA) FOR SPAM DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff299a52-90b5-4bda-bd5b-2281eca6f58d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f81e302-ed9e-490d-93c4-25707db96722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/fbb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "import random\n",
    "import abc\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33e113-6080-4673-abf2-8d81a6ac2da9",
   "metadata": {},
   "source": [
    "## Start with the data extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24d71f82-dca0-4758-bd3c-a081bd9d7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction(file_path=\"Data/SMSSpamCollection\"):\n",
    "    \"\"\"\n",
    "    Given a filepath, extract the data within the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = [line.strip() for line in f]\n",
    "            return data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: File not found at {filepath}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "059d4ff6-a151-4414-b5ee-237ebf4e222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data, stop_words):\n",
    "    \"\"\"\n",
    "    Given the data, return tuple of data and label\n",
    "    \"\"\"\n",
    "    finished_data =[]\n",
    "    for sms in data:\n",
    "        label, text = sms.split(\"\\t\")\n",
    "        text = text.lower()\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        text = text.replace('\\x92', \"'\")\n",
    "        words = text.split()\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        text = \" \".join(words)\n",
    "        finished_data.append((label, text))\n",
    "    return finished_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc33a225-7329-4ddb-955b-61050709c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "ham\tOk lar... Joking wif u oni...\n",
      "('ham', 'go jurong point crazy available bugis n great world la e buffet cine got amore wat')\n",
      "('ham', 'ok lar joking wif u oni')\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Data/SMSSpamCollection\"\n",
    "\n",
    "data = data_extraction(file_path)\n",
    "print(data[0])\n",
    "print(data[1])\n",
    "\n",
    "data = data_processing(data, stop_words)\n",
    "print(data[0])\n",
    "print(data[1])\n",
    "#print(data[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d2d9b-9329-46f4-9cec-adaa2e8a5dad",
   "metadata": {},
   "source": [
    "## Get some statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "533e91fd-1b94-49c0-90cf-c02d0eb0a282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contains 747 spam messages\n",
      "The data contains 4827 harmless messages\n"
     ]
    }
   ],
   "source": [
    "count_of_spam = 0\n",
    "for label, _ in data:\n",
    "    if label == 'spam':\n",
    "        count_of_spam += 1\n",
    "count_of_ham = len(data) - count_of_spam\n",
    "\n",
    "print(f\"The data contains {count_of_spam} spam messages\")\n",
    "print(f\"The data contains {count_of_ham} harmless messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a4595a-3f8f-4b7b-95e4-899de8f752ea",
   "metadata": {},
   "source": [
    "## The NSA Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3867a909-d71e-40b3-9497-06db405f811e",
   "metadata": {},
   "source": [
    "The basic idea is to create a detector based only on the self, so the strings which are not harmful. So the detector is trained on random strings, which are matched against the 'ham' labeled data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb086f6-0e5a-4b32-8719-88da5f9ec87e",
   "metadata": {},
   "source": [
    "### The abstract class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e67e67-a8a9-4b9b-9908-e1469ae380c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSA(abc.ABC):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def encode(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def generate_detectors(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def run(self):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def detect_with_detectors(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a4c91-6c3a-421e-8e0c-4e10aff197d8",
   "metadata": {},
   "source": [
    "### K-Grams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85838ef-567b-4e86-8102-1051ad447250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class k_gram_NSA(NSA):\n",
    "\n",
    "    def __init__(self, r):\n",
    "        self.r = r\n",
    "\n",
    "    def encode(self, data):\n",
    "        k_grams = set()\n",
    "        for label, sms in data:\n",
    "            if label == 'spam':\n",
    "                continue\n",
    "            if len(sms) < self.r:\n",
    "                continue\n",
    "            for i in range(len(sms) - self.r + 1):\n",
    "                k_grams.add(sms[i:i+self.r])\n",
    "        return k_grams\n",
    "\n",
    "    def random_string(self, alphabet):\n",
    "        return ''.join(random.choice(alphabet) for _ in range(self.r))\n",
    "\n",
    "    def generate_detectors(self, k_grams, num_detectors, alphabet=None, max_iters=1000):\n",
    "        if alphabet == None:\n",
    "            alphabet = string.ascii_lowercase + string.digits\n",
    "        detectors = set()\n",
    "        iters = 0\n",
    "        while len(detectors) < num_detectors and iters < max_iters:\n",
    "            iters += 1\n",
    "            cand = self.random_string(alphabet)\n",
    "            if cand not in k_grams:\n",
    "                detectors.add(cand)\n",
    "        if len(detectors) < num_detectors:\n",
    "            print(\"Warning: could only generate\", len(detectors), \"detectors after\", iters, \"iters.\")\n",
    "        self.len_detector = len(detectors)\n",
    "        return list(detectors)\n",
    "\n",
    "    def detect_with_detectors(self, message, detectors):\n",
    "        for d in detectors:\n",
    "            if d in message:\n",
    "                return True, d\n",
    "        return (False, None)    \n",
    "\n",
    "    def run(self, data):\n",
    "        k_grams = self.encode(data)\n",
    "        detectors = self.generate_detectors(k_grams,5000, max_iters=10000)\n",
    "        anomalies = []\n",
    "        for label, sms in data:\n",
    "            anomalies.append((label, self.detect_with_detectors(sms, detectors)))\n",
    "        return anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed2b79-07e1-479c-899c-f04e3d224716",
   "metadata": {},
   "source": [
    "### K-Grams with binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6a8d69-6adc-460f-a4a3-9aed8f0bbacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TO BE IMPLEMENTED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f315809-1a19-45f3-9acf-4b9af1caadb6",
   "metadata": {},
   "source": [
    "### Model Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "272ef21c-0fcf-475b-b9ec-d86994d118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_stats(accuracy, precision, recall, f1_score):\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1_score}\")\n",
    "\n",
    "def print_mean_model_stats(stats):\n",
    "    accuracy, precision, recall, f1_score = stats\n",
    "    print(f\"Mean Accuracy: {accuracy}\")\n",
    "    print(f\"Mean Precision: {precision}\")\n",
    "    print(f\"Mean Recall: {recall}\")\n",
    "    print(f\"Mean F1-Score: {f1_score}\")\n",
    "\n",
    "\n",
    "def model_stats(results):\n",
    "    pred_count = 0\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for result in results:\n",
    "        label, pred = result\n",
    "        if pred[0]:\n",
    "            pred_count += 1\n",
    "            if label == 'spam':\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        if not pred[0]:\n",
    "            if label == 'spam':\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    accuracy = (TP + TN) / len(results)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "def mean_stats_calc(stats):\n",
    "    num_runs = len(stats)\n",
    "    total_accuracy = sum(acc for acc, _, _, _ in stats)\n",
    "    total_precision = sum(pre for _, pre, _, _ in stats)\n",
    "    total_recall = sum(rec for _, _, rec, _ in stats)\n",
    "    total_f1 = sum(f1 for _, _, _, f1 in stats)\n",
    "    \n",
    "    mean_acc = total_accuracy / num_runs\n",
    "    mean_pre = total_precision / num_runs\n",
    "    mean_rec = total_recall / num_runs\n",
    "    mean_f1 = total_f1 / num_runs\n",
    "\n",
    "    return mean_acc, mean_pre, mean_rec, mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1f3ae31-e053-4d57-8e01-46dd7b9078a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running K-Grams NSA with r = 2\n",
      "Warning: could only generate 507 detectors after 10000 iters.\n",
      "Warning: could only generate 507 detectors after 10000 iters.\n",
      "Warning: could only generate 507 detectors after 10000 iters.\n",
      "Warning: could only generate 507 detectors after 10000 iters.\n",
      "Warning: could only generate 507 detectors after 10000 iters.\n",
      "Mean Accuracy: 0.97918909221385\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 0.8447121820615797\n",
      "Mean F1-Score: 0.9158200290275762\n",
      "Running K-Grams NSA with r = 3\n",
      "Mean Accuracy: 0.957481162540366\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 0.6827309236947791\n",
      "Mean F1-Score: 0.8102445118512727\n",
      "Running K-Grams NSA with r = 4\n",
      "Mean Accuracy: 0.8712235378543237\n",
      "Mean Precision: 1.0\n",
      "Mean Recall: 0.03908969210174029\n",
      "Mean F1-Score: 0.07480918393062388\n"
     ]
    }
   ],
   "source": [
    "r_range = range(2,5)\n",
    "test_runs = 5\n",
    "mean_stats = []\n",
    "\n",
    "for i in r_range:\n",
    "    print(f\"Running K-Grams NSA with r = {i}\")\n",
    "    stats_in_r = []\n",
    "    for _ in range(test_runs):\n",
    "        k_grams_nsa = k_gram_NSA(i)\n",
    "        stats_in_r.append(model_stats(k_grams_nsa.run(data)))\n",
    "    means = mean_stats_calc(stats_in_r)\n",
    "    mean_stats.append(means)\n",
    "    print_mean_model_stats(means)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
